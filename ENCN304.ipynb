{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca79e42c",
   "metadata": {},
   "source": [
    "# Power Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96996fad",
   "metadata": {},
   "source": [
    "The power method is an iterative technique for estimating the eigenvalues and eigenvectors of a matrix.\n",
    "\n",
    "For the matrix $A$, and initial guess of the eigenvector, $\\mathbf{x}_0$, we obtain subsequent guesses.\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{x}_{k+1} = \\frac{A\\mathbf{x}_k}{|A\\mathbf{x}_k|},\\quad\\quad\\lambda_1 \\approx \\frac{\\mathbf{x}_{k+1}^TA\\mathbf{x}_{k+1}}{\\mathbf{x}_{k+1}^T\\mathbf{x}_{k+1}}\n",
    "\\end{equation}\n",
    "\n",
    "The example below shows successive estimates of the eigenvector and eigenvalue for subsequent iterations of the power method. Try changing the starting vector, and see how the error reduces with each iteration. Error is estimated by the angle between eigenvector estimates in successive iterations, $\\Delta\\theta$.\n",
    "\n",
    "Consider the case below, which is also used in the notes\n",
    "\n",
    "$$A=\\begin{bmatrix} 1 & 2 \\\\ 2 & 1 \\end{bmatrix}, \\quad\\quad \\mathbf{x}_0=\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$$\n",
    "\n",
    "***Run the cell below by clicking to highlight it green, and then hitting Ctrl+Enter***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57f3c2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from encn304 import power_method\n",
    "power_method()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1333edb",
   "metadata": {},
   "source": [
    "# Earthquake Building Response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89be835d",
   "metadata": {},
   "source": [
    "The earthquake response problem in pages 28 to 31 of the notes involves the solution to a coupled set of 2nd order ODEs, one for each floor of a building. The method to obtain a solution is given in detail, here we just show the solution itself.\n",
    "\n",
    "\\begin{equation}\n",
    "\\mathbf{x} = c_1\\mathbf{v}_1 \\cos(\\omega_1 t+\\phi_1)+c_2\\mathbf{v}_2 \\cos(\\omega_2 t+\\phi_2)+c_3\\mathbf{v}_3 \\cos(\\omega_3 t+\\phi_3)\n",
    "\\end{equation}\n",
    "\n",
    "where:\n",
    "- indices $1$-$3$ refer to the individual floors;\n",
    "- $\\omega_i=\\sqrt{\\lambda_i}$ are the harmonic frequencies, related to the eigenvalues;\n",
    "- $\\mathbf{v}_i$ are the characteristic displacements (eigenvectors), and;\n",
    "- $c_i$ and $\\phi_i$ are determined by initial position ($\\mathbf{x}_0$) and velocity conditions ($\\dot{\\mathbf{x}}_0$).\n",
    "\n",
    "If the initial velocity is zero, we can show that $\\phi_i$=0 and $\\mathbf{c}=V^{-1}\\mathbf{x_0}$.\n",
    "\n",
    "The solution is shown below. Although it appears chaotic, it is only a simple sum of three oscillators.\n",
    "\n",
    "***Run the cell below by highlighting it and hitting Ctrl+Enter.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba7857e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from encn304 import earthquake_response\n",
    "earthquake_response()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d671c5",
   "metadata": {},
   "source": [
    "# Euler's Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377ffb2e",
   "metadata": {},
   "source": [
    "Time-marching methods examined in this course match the derivatives in a **Taylor's expansion** over a finite region to some order. The omission of **higher-order** Taylor series terms in the approximation means that each method will have an associated **error**.  The **Euler method** is the simplest in that it only approximates the first derivative of the function. It does this using a first-order **finite difference** approximation to the derivative.\n",
    "\n",
    "Supposing the ODE can be written in the form\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{dx}{dt} = f(t,x(t))\n",
    "\\end{equation}\n",
    "\n",
    "then the finite difference approximation to the derivative is:\n",
    "\n",
    "\\begin{equation}\n",
    "  \\frac{dx}{dt} \\thickapprox \\dfrac{\\Delta x}{\\Delta t} = \\dfrac{x(t+\\Delta t) - x(t)}{\\Delta t} = f\\left(t,x(t)\\right)\n",
    "\\end{equation}\n",
    "\n",
    "This can be rearranged to give\n",
    "\n",
    "\\begin{equation}\n",
    "  x(t+\\Delta t) = x(t) + \\Delta t\\,f\\left(t,x(t)\\right).\n",
    "\\end{equation}\n",
    "\n",
    "In terms of an iterating index, $k$, Euler's method is written\n",
    "\n",
    "\\begin{equation}\n",
    "  x^{(k+1)} = x^{(k)} + \\Delta t\\,f^{(k)},\\quad\\quad\\quad\\quad f^{(k)}=f\\left(t^{(k)},x^{(k)}\\right), \\quad\\quad\\quad\\quad t^{(k+1)}=t^{(k)}+\\Delta t\n",
    "\\end{equation}\n",
    "\n",
    "The example below shows, step-by-step, how Euler's method is applied for the ODE\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{dx}{dt} = (1+tx)^2\n",
    "\\end{equation}\n",
    "\n",
    "Unlike most examples in this course, this ODE is **non-linear**, which means there is no analytical solution to compare against.\n",
    "\n",
    "***Run the cell below by highlighting it and hitting Ctrl+Enter***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8b835e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from encn304 import euler_method\n",
    "euler_method()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d9c4f4",
   "metadata": {},
   "source": [
    "# Euler error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b5e429",
   "metadata": {},
   "source": [
    "The exercise below attempts to solve the ODE\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{dx}{dt} = \\sin\\left(a\\sin(t)\\sqrt{t}+\\frac{\\cos(bt)}{t+1}\\right)\n",
    "\\end{equation}\n",
    "\n",
    "with $a$=8 and $b$=8.5. However, we should be mindful of the tradeoff between **efficiency and accuracy** (or effort and error).\n",
    "\n",
    "***Execute the cell below. Experiment with the input boxes.***\n",
    "\n",
    "***In general, how many steps are required to get the error below 5%?***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467046e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from encn304 import euler_error\n",
    "euler_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b6183f",
   "metadata": {},
   "source": [
    "# Euler stability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4db5766",
   "metadata": {},
   "source": [
    "Consider the simple ODE $x' = \\lambda x$, which we know has an exponential solution. For the case that $\\lambda <0$, the solution should decay to zero.\n",
    "\n",
    "The Euler update step is \n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "x^{(k+1)} &=&\\,x^{(k)} + \\lambda \\,\\Delta t\\,x^{(k)} \\\\\n",
    "&=&\\,\\left(1+\\lambda \\Delta t\\right)x^{(k)} \\\\\n",
    "&=&\\,\\left(1+\\lambda \\Delta t\\right)^k x^{(0)}.\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "If $|1+\\lambda \\Delta t|>1$ then $x^{(k)}$ will keep increasing in value rather than decaying to 0. This defines a **stability criterion** for Euler's method applied to this problem: $-1 < 1+\\lambda \\Delta t < 1 \\Rightarrow 1 + \\lambda \\Delta t > -1 \\Rightarrow \\lambda \\Delta t > -2 \\Rightarrow \\Delta t < - \\dfrac{2}{\\lambda }$.  Therefore the stability criterion for the Euler method to give stable solutions for this problem is $\\Delta t < -\\dfrac{2}{\\lambda }$.\n",
    "\n",
    "***Run the cell below with Ctrl+Enter***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "935da55d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac903400776a490a8fc344251f049c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=15, description='steps', max=15, min=3), Dropdown(description='mâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from encn304 import euler_stability\n",
    "euler_stability()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877266e2",
   "metadata": {},
   "source": [
    "# Implicit methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f911b86",
   "metadata": {},
   "source": [
    "An issue with the methods we have looked so far is their stability in non-linear problems. If the function is changing rapidly, it will have a large derivative. Using the estimate of the derivative at the current value of the solution and 'jumping ahead' can run the risk that we greatly overshoot. An unstable problem will compound these overshoots.\n",
    "\n",
    "Methods that use the current estimate of the gradient to jump ahead are called **Explicit** methods.\n",
    "\n",
    "But what if we could use the derivative in the future, at the end of the time step? This partly solves the overshoot problem, but it also puts the horse before the cart. How can we know the derivative in the future if we haven't taken a step there yet?\n",
    "\n",
    "**Implicit** methods involve iteratively guessing a future solution that, when we calculate its derivative, draws a line connecting back to our current step. Usually, the first guess is wrong, which means we need to keep calculating updates until it is appropximately correct.\n",
    "\n",
    "Thus, backward Euler is defined\n",
    "\n",
    "$$ x_{n+1} = x_{n}+\\Delta t f(t_{n+1}, x_{n+1})$$\n",
    "\n",
    "which is almost identical to the regular Euler method, except that the derivative is evaluated at $f(t_{n+1}, x_{n+1})$ instead of $f(t_{n}, x_{n})$.\n",
    "\n",
    "***Run the cell below for an demonstration of how the Backward Euler method works.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98201712",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b50b7e0952428a945583455f0b48df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(FloatSlider(value=7.25, description='steps', max=9.0, min=1.25, step=0.25), Checâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from encn304 import backward_euler\n",
    "backward_euler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa0c190",
   "metadata": {},
   "source": [
    "How should we get these future guesses and update them? There are a number of strategies. We'll look at a simple one called **predictor-corrector**, or **function iteration**. The basic strategy is:\n",
    "1. Use a standard Euler step to guess the future: $x_{n+1}^{(0)}$. This is called the **predictor**.\n",
    "2. Evaluate the gradient at the future guess: $f(t_{n+1}, x_{n+1}^{(0)})$\n",
    "3. Use the backward Euler step to update the guess of the future: $x_{n+1}^{(1)} = x_{n}+\\Delta t f(t_{n+1}, x_{n+1}^{(0)})$. This is called the **corrector**.\n",
    "4. Keep updating in this manner: $x_{n+1}^{(i+1)} = x_{n}+\\Delta t f(t_{n+1}, x_{n+1}^{(i)})$. Each time, we obtain a better **corrector**.\n",
    "5. Stop updating when the change from one guess to the next is small: $|x_{n+1}^{(i+1)}-x_{n+1}^{(i)}|<\\epsilon$\n",
    "6. Accept $x_{n+1}^{(i+1)}$ as the next step and restart the iteration to estimate $x_{n+2}$.\n",
    "\n",
    "Final note: because this method uses an Euler step, it is still subject to the conditional stability of the Euler method. Which would seem to defeat the purpose, because the principle advantage of implicit methods is supposed to be their unconditional stability. There are more complex versions of Backward Euler that use **Newton Iteration** instead of function iteration. Although these are unconditionally stable, they are too difficult for us to implement here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c154e9ff",
   "metadata": {},
   "source": [
    "# Trapezium Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9deb85c9",
   "metadata": {},
   "source": [
    "Why do we need numerical methods for integration? Have a go at solving the integral below. \n",
    "\n",
    "$$ \\int \\frac{\\sin\\left(\\frac{c_0\\,\\cos(x)+c_1\\,\\sin(x)}{\\cos(x)}\\right)}{c_0\\,\\cos(x)+c_1\\,\\sin(x)}dx$$\n",
    "\n",
    "**Not all integrals can be solved analytically.** Take the general integral $I=\\int\\limits_{a}^{b}f(x)\\,dx$, where we know $f(x)$ as the **integrand**.\n",
    "\n",
    "We shall consider a class of methods that approximately evaluate this integral. These methods are based on the idea that the value of an integral, $I$, corresponds to the area under the graph of the integrand. There are two cases:\n",
    "1. We **know** the integrand, $f(x)$, exactly.\n",
    "2. We **don't know** $f(x)$ exactly, but we do have some data, $(x_i, y_i)$. Therefore, we can find an interpolating function, $g(x)\\approx f(x)$.\n",
    "\n",
    "Numerical integration methods break the integration range into subintervals and then computes the area of each. If $f(x)$ is known, then the subintervals can be chosen. Otherwise, the subintervals are defined by the data locations $x_i$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "172d1824",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57e26f01885a4f94aef1190b8e3f1be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(Checkbox(value=False, description='$f(x)$ known'), Checkbox(valueâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from encn304 import trapezium\n",
    "trapezium()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
